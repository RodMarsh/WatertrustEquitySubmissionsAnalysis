# Topic modelling of submissions to identify frames

Can we triangulate the frames identified by the actor-keyword analysis through
the application of topic modelling across all submissions? The aim of this is
to explore how frames may persist or be used across different actor groups, 
rather than be specifically tied into or constructed by specific groups.

```{r eval=FALSE}
install.packages("RSQLite")
install.packages("writexl")
install.packages("tidyverse")
install.packages("seededlda")
install.packages("xtable")
install.packages("pheatmap")
```

# Load and prepare are submission data as extracted from the various inquiries
```{r}
library(DBI)
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(seededlda)
library(writexl)
library(xtable)
library(pheatmap)

inquiries <- dbConnect(RSQLite::SQLite(), "../inquiries/inquiries.db")
submissions <- dbGetQuery(inquiries, 
  'SELECT submission.*, submission_label.label, context FROM submission
  inner join submission_label using(inquiry_shortname, submission_id)
  inner join inquiry using(inquiry_shortname)
  where priority = 1
  '
) %>% mutate(text = gsub("[‘’]", "'", text))

# Generate a single column unique id - this is the composite primary key
# defined in the database, so will always be unique. This is used to tie
# together results at different granularities.
submissions$doc_id <- paste(submissions$inquiry_shortname, submissions$submission_id)
submission_corpus <- corpus(submissions, text_field="text", docid_field = "doc_id")

dbDisconnect(inquiries)

```

# Construct document-feature matrix specific for topic models

Note that the feature processing and tokenisation pipeline is the same as used
in the concordance and keyword analysis, with a few additional stopwords to
handle features that complicate topic analysis but did not impact on keyword
analysis. Unlike the keyword analysis the stopword list is more limited and
does not include genre-indicator words: these cluster together as topics 
enabling them to be more easily filtered.

```{r}

# These are the byproducts of extracting text from the PDF where images are
# included.
pdf_processing_words <- c(
  'image',
  'height',
  'width',
  'rgb',
  'srgb',
  'bpc',
  '16',
  'iccbased'
)

# Additional words that can be prominent in topics but did not matter for 
# keyword analysis.
topic_model_specific_words <- c(
  "water",
  "murray",
  "darling",
  "basin",
  "plan",
  "river"
)

extended_stopwords <- c(
  pdf_processing_words,
  topic_model_specific_words,
  stopwords("english")
)

submission_tokens <- tokens(
    submission_corpus, remove_punct=TRUE, split_hyphens = TRUE, remove_symbols = TRUE
  ) %>% 
  tokens_remove(extended_stopwords, min_nchar=2)

# Only consider words that appear in at least 10 submissions overall.
submissions_dfm <- dfm_trim(dfm(submission_tokens), min_docfreq=10)
```

# Generate topic models, and construct summary and prevalence estimates

Generates topic model with a large number of topics, and includes a basic 
summary of the prevalent words in each topic, and the estimated 'prevalence' of
that topic across all of the documents in the collection.

```{r}

# Set the seed for topic modelling consistency from run to run
set.seed(1618269559)
# Generate the topic model, with a large number of topics to enable filtering.
# Note that this is slow - we could use the parallel implementation, but it is
# non deterministic from run to run, even with the seed set.
submissions_lda <- textmodel_lda(submissions_dfm, k=30, auto_iter=TRUE)
results <- terms(submissions_lda, n=20) %>% 
  as.data.frame() %>%
  pivot_longer(everything(), names_to="topic") %>%
  group_by(topic) %>%
  summarise(features = paste0(value, collapse=", "))

# Organise topics by prevalence - this is the sum of all of the topic proportions
# for each topic - higher numbers indicate that proportionally more of documents
# were generated by drawing from that topic mixture.
relative_prevalence <- colSums(submissions_lda$theta) / sum(submissions_lda$theta) %>%
  sort(decreasing=TRUE) 

# convert named vector back to a long format data frame
relative_prevalence <- cbind(read.table(text = names(relative_prevalence)), relative_prevalence)

# Glue back together
topic_word_prevalence <- results %>% 
  inner_join(relative_prevalence, by=join_by(topic == V1)) %>%
  arrange(desc(relative_prevalence))

write_xlsx(topic_word_prevalence, '../results/topic_words_prevalence.xlsx')

```

# Topic prevalence by groups and inquiries

Topic prevalence for documents can be broken down to show the usage across 
groups (indicating potential frame takeup by groups), or across inquiries (
indicating that a topic might be responsive to the terms-of-reference or issues
raised in an inquiry).

These visualisations illustrate topic prevalence by groups and also by 
inquiries.

```{r}

# Assign topic words as names for easier preliminary inspection
topic_row_names <- terms(submissions_lda, n=3) %>% 
  as.data.frame() %>%
  pivot_longer(everything(), names_to="topic") %>%
  group_by(topic) %>%
  summarise(features = paste0(value, collapse=", ")) %>%
  mutate(features = paste0(regmatches(topic, regexpr("[0-9]+", topic)), ": ", features), sep="")

# Get topic-document matrix and put it back together with the submission
# variables so we can aggregate by submitter group and inquiry.
doc_topics <- submissions_lda$theta %>% 
  as.data.frame()

# Make the doc_id column explicit
doc_topics$doc_id <- rownames(doc_topics)

# Pivot to long for averages in the next step
doc_topics <- doc_topics %>%
  pivot_longer(!doc_id, values_to="proportion", names_to="topic")

# Join the relevant metadata for easier aggregation
doc_topics <- doc_topics %>% 
  inner_join(
    submissions %>% select(doc_id, label, inquiry_shortname, submitter, url),
    by = join_by(doc_id == doc_id)
  ) %>%
  inner_join(topic_row_names, by=join_by(topic))

# While we're here, for each topic, find the submitters of the 10 documents with 
# the highest estimated prevalence.
top_docs_by_topic <- doc_topics %>% 
  group_by(topic) %>%
  slice_max(proportion, n=10) %>%
  arrange(desc(proportion), .by_group = TRUE)

write_xlsx(top_docs_by_topic, "../results/top_docs_by_topic.xlsx")

# Also for tabulation purposes, the same data, but only three submitters
top_docs_by_topic_small <- doc_topics %>% 
  group_by(topic) %>%
  slice_max(proportion, n=3) %>%
  arrange(desc(proportion), .by_group = TRUE) %>%
  summarise(submitters = paste0(submitter, collapse=", "))

topic_table <- topic_word_prevalence %>% 
  inner_join(top_docs_by_topic_small, by=join_by(topic))

# Rewrite so the topic ids are numerical
topic_table$topic <- regmatches(topic_table$topic, regexpr("[0-9]+", topic_table$topic))

write_xlsx(topic_table, '../results/topic_overview.xlsx')
print(xtable(topic_table, digits=3), include.rownames=FALSE)

# Aggregate prevalence by group
aggregated_topics <- doc_topics %>%
  group_by(label, features) %>%
  summarise(topic_proportion=mean(proportion), .groups="keep")

heatmap <- aggregated_topics %>%
  pivot_wider(names_from = label, values_from=topic_proportion, id_cols=features)
heatmap <- column_to_rownames(heatmap, var="features")

# Cosine similarity of a matrix with itself, treating each row as a vector
cosine_topic_similarity <- function(mat){
  row_norms <- sqrt(rowSums(mat ^ 2))
  normalised_mat <- mat / row_norms
  return (normalised_mat %*% t(normalised_mat))
} 

# Distance between topics is based on the similarity of the topic-term
# probability distributions
topic_words <- submissions_lda$phi

# Note these aren't in the same order so the renaming requires a lookup
# and we also need to make sure that the heatmap and the topics have the
# same order, as the clustering is referenced by index not name.
name_order <- match(rownames(topic_words), topic_row_names$topic)
rownames(topic_words) <- topic_row_names$features[name_order]

# Order the heatmap columns in the same was as we will order the topics in the
# topic similarity map.
ordering <- match(rownames(topic_words), rownames(heatmap))
heatmap <- heatmap[ordering, ]

topic_dist_similarity <- cosine_topic_similarity(topic_words)

# Generate clustering for heatmaps
topic_clustering <- hclust(as.dist(1 - topic_dist_similarity))

n_clusters = 5

gradient = colorRampPalette(c("white", "#1053f9"), space="Lab")(20)

pheatmap((heatmap * 100) %>% as.matrix(), 
  color=gradient,
  cluster_rows=topic_clustering, 
  cluster_cols=FALSE,
  angle_col=45,
  cellwidth = 15, cellheight = 15, 
  main = "Topic Prevalence by Group",
  filename = "../results/topics_group_heatmap.pdf",
  width = 7, height = 8,
  legend = TRUE,
  legend_break = c(10, 20, 30, 35),
  legend_labels = c("10", "20", "30", "%"),
  labels_col = c(
    "commercial, non con", 
    "agricultural", 
    "electedrep", 
    "environmental", 
    "firstnations", 
    "government", 
    "not categorisable",
    "regional",  
    "research", 
    "resource managers"
  ),
  cutree_rows = n_clusters
)

pheatmap(topic_dist_similarity,
  cluster_rows=topic_clustering, 
  cluster_cols=topic_clustering,
  color=gradient,
  angle_col=45,
  cellwidth = 16, cellheight = 16, 
  main = "Topic Distributional Similarities",
  filename = "../results/topic_similarities.pdf",
  width = 10.5, height = 10,
  legend = FALSE,
  cutree_rows = n_clusters,
  cutree_cols = n_clusters
)

```

# What about explicit notions of equity, fairness and justice?

To examine the explicit ways that fairness terms interrelate with topics, we
identify for each of the selected set of words for fairness the ordering of
topics that it is most prevalent in.

```{r}


# The commented terms were checked but aren't present (potentially they were)
# filtered out by the number of docs checked.
fairness_terms <- c(
  "fairness",
  "unfair",
  # "unfairness",
  "unfairly",
  "fair",
  "equity",
  "equitable",
  "inequitable",
  "inequity",
  # "unequitable",
  "justice",
  "injustice",
  "injustices",
  "unjust"
)

fairness_topic_weights <- topic_words[,fairness_terms] * 100

pheatmap(fairness_topic_weights,
  cluster_rows=topic_clustering, 
  cluster_cols=FALSE,
  color=gradient,
  angle_col=45,
  cellwidth = 15, cellheight = 15, 
  main = "Weight of Fairness Terms by Topic",
  filename = "../results/topic_efj_weights.pdf",
  width = 7, height = 7.5,
  legend = TRUE,
  legend_break = c(0.05, 0.1, 0.15, 0.2, 0.225),
  legend_labels = c("0.05", "0.10", "0.15", "0.20", "%"),
  cutree_rows = n_clusters
)

write_xlsx(fairness_topic_weights %>% as.data.frame(), "../results/fairness_topic_weights.xlsx")

    
```

# Aggregating topics together based on the clustering

Final heatmap, showing topic prevalence aggregated up a few levels to avoid
the overload of trying to look at 30 x n heatmaps

```{r}

cut_clusters = cutree(topic_clustering, k = n_clusters)


merge_rows <- function(i, array, combinations){
  return(colSums(array[combinations == i, ]))
}

sapply(unique(cut_clusters), merge_rows, array = submissions_lda$phi, combinations=cut_clusters)

sapply(unique(cut_clusters), merge_rows, array = t(submissions_lda$theta), combinations=cut_clusters)



```



